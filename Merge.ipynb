{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0bb03fd57f0abe20aaa44405faada2d45c76eeb8f5b4a3cb120ceb3cb1a26d008",
   "display_name": "Python 3.9.2 64-bit ('bachelor_thesis': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import followthemoney as ftm\n",
    "from followthemoney.cli.util import read_entities\n",
    "import followthemoney_enrich as ftm_enrich\n",
    "import followthemoney.model as model\n",
    "from followthemoney.dedupe import Match, Linker\n",
    "import json\n",
    "import pandas as pd\n",
    "import gdown\n",
    "import alephclient"
   ]
  },
  {
   "source": [
    "# Overview\n",
    "\n",
    "Here I will go throught the steps of merging two collections according to the following architecture.\n",
    "\n",
    "!<img src=\"./img/architecture.JPG\" width=\"400\" />\n",
    "\n",
    "For this evaluation, this is done with the [everypolitician](http://everypolitician.org) dataset, which has been mapped to the FtM ontology by an existing [scraper](https://github.com/pudo/opensanctions/blob/main/opensanctions/crawlers/everypolitician.py).\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Prerequesite: Data to reconcile\n",
    "This uploads data to a private Aleph instance to allow the user to interactively reconcile. In natural setting, this is automated via OpenSanctions.\n",
    "\n",
    "The following only works if an Aleph instance is running and the API key belongs an admin, as otherwise collections are not mutable when uploaded through the CLI. This constrain applies only to scraped scripts. The reconciliation of mapped entities from documents mappings or manually created ones works all the time for any user."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabled = \"./data/meineabgeordneten_agg.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "host=\"http://localhost:3000\"\n",
    "api_key=\"lUuPrgpmvqM24Mktqbtefw8cmPGY9U4ky0eotN44Kbc\" \n",
    "collection_id = \"ce6318ac176844bf90410c83d7e1cd87\"\n",
    "target_collection_id = \"4b713bcbe372492894529764d7f8096e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:alephclient.cli:[ce6318ac176844bf90410c83d7e1cd87] Bulk load entities: 1000...\nINFO:alephclient.cli:[ce6318ac176844bf90410c83d7e1cd87] Bulk load entities: 2000...\nINFO:alephclient.cli:[ce6318ac176844bf90410c83d7e1cd87] Bulk load entities: 3000...\nINFO:alephclient.cli:[ce6318ac176844bf90410c83d7e1cd87] Bulk load entities: 4000...\nINFO:alephclient.cli:[ce6318ac176844bf90410c83d7e1cd87] Bulk load entities: 5000...\nINFO:alephclient.cli:[ce6318ac176844bf90410c83d7e1cd87] Bulk load entities: 6000...\nINFO:alephclient.cli:[ce6318ac176844bf90410c83d7e1cd87] Bulk load entities: 7000...\nINFO:alephclient.cli:[ce6318ac176844bf90410c83d7e1cd87] Bulk load entities: 8000...\nINFO:alephclient.cli:[ce6318ac176844bf90410c83d7e1cd87] Bulk load entities: 9000...\nINFO:alephclient.cli:[ce6318ac176844bf90410c83d7e1cd87] Bulk load entities: 10000...\nINFO:alephclient.cli:[ce6318ac176844bf90410c83d7e1cd87] Bulk load entities: 11000...\nINFO:alephclient.cli:[ce6318ac176844bf90410c83d7e1cd87] Bulk load entities: 12000...\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$host\" \"$api_key\" \"$collection_id\" \"$unlabled\"\n",
    "alephclient --host $1 --api-key $2 write-entities -i $4 -f $3"
   ]
  },
  {
   "source": [
    "# Get Data\n",
    "In a normal setting, one would load two collection by using the CLI.\n",
    "\n",
    "```\n",
    "alephclient --host https://aleph.occrp.org --api-key <api-key> stream-entities -f <collection-id> -o <outfile>\n",
    "```\n",
    "\n",
    "\n",
    " \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$host\" \"$api_key\" \"$collection_id\" \n",
    "alephclient --host $1 --api-key $2 stream-entities -f $3 | ftm aggregate -o data/output/mein_abg_aleph.json "
   ]
  },
  {
   "source": [
    "For reproducibility, this has been done in advance."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/output/\"\n",
    "ep_path = path + \"everypolitician.json\"\n",
    "# Person entities reconciled against Wikidata.\n",
    "ma_path = path + \"meineabgeordneten_wikidata.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/u/0/uc?id=1YNQKfm6qLKb5M6cfNrk9m8UYwi4iOxdF\n",
      "To: /home/peter/dev/evaluation_bachelor_thesis/data/output/everypolitician.json\n",
      "127MB [00:09, 13.1MB/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'./data/output/everypolitician.json'"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "# Everypolitician file snapshot, which is too big for git.\n",
    "gdown.download(\"https://drive.google.com/u/0/uc?id=1YNQKfm6qLKb5M6cfNrk9m8UYwi4iOxdF\", ep_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ftm_json(path, filter = \"Person\"):\n",
    "    entity_dict = {}\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            entity = model.get_proxy(json.loads(line))\n",
    "            wd = entity.first(\"wikidataId\", True)\n",
    "            if entity.schema.name == filter:\n",
    "                entity_dict[wd] = entity\n",
    "    return entity_dict\n",
    "path = \"./data/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mein_abg = read_ftm_json(ma_path)\n",
    "every_polit = read_ftm_json(ep_path)"
   ]
  },
  {
   "source": [
    "# Matching\n",
    "We will check for equal Wikidata IDs and create a Match object. A match objects holds two entity IDs and a decision about the sameness. This match object could be uploaded to Aleph via the API. However, we will use it to perfom it instantly."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "enricher = ftm_enrich.enricher.Enricher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matches = []\n",
    "for idx, polit in every_polit.items():\n",
    "    abg = mein_abg.get(idx)\n",
    "    if abg:\n",
    "        #print(polit.to_dict())\n",
    "        match = enricher.make_match(abg, polit)\n",
    "        match = Match(model, {})\n",
    "        match.entity=  abg\n",
    "        match.canonical =  polit\n",
    "        match.decision = match.SAME\n",
    "        matches.append(match)\n"
   ]
  },
  {
   "source": [
    "In total, there are 77 matching person entities with respect to the wikidata ID."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "len(matches)"
   ]
  },
  {
   "source": [
    "# Merging\n",
    "The merging logic actually exists in the FtM [repository](https://github.com/alephdata/followthemoney/blob/6cb55e319f69443dff17bf1ee5dd1a37a31b5c4a/followthemoney/cli/dedupe.py) and works the following:\n",
    "\n",
    "1. Create a linker object, which takes match objects and checks if there is a sameness decision.\n",
    "2. If so, add the pair to a hashmap (Python dict) in the linker object.\n",
    "3. Iterate through both collection of to-be-merged entities and pass each entity to the linker object (which knows the links). If the entity's ID is stored in the hashmap, adopt the entity ID. If not, keep the ID. This also applies for \"edges\", such as memberships.\n",
    "4. Write to file. \n",
    "5. As we have duplicates, we aggregate, which merges items with the same ID. Merging just unions both, properties and their values. Therefore, same properties are merged, and different ones are just added to the multi-valued list."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Example on how it works"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'a': '891bd4dbcf5506d489f8d6e757ace9411eccee55',\n",
       " 'b': 'a21072d75aebf5f72865a70ca9e10beffb9ddb27',\n",
       " 'merged': '891bd4dbcf5506d489f8d6e757ace9411eccee55',\n",
       " 'result': {'name': ['Prof. Dr. hans kelsen', 'hans kelsen'],\n",
       "  'title': ['Dr', 'Prof.'],\n",
       "  'birthDate': ['1908-07-06', '1908']}}"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "linker_exmpl = Linker(model)\n",
    "\n",
    "a = ftm.model.make_entity(\"Person\")\n",
    "a.add(\"name\", \"hans kelsen\")\n",
    "a.add(\"title\", \"Dr\")\n",
    "a.add(\"birthDate\", \"1908-07-06\")\n",
    "a.make_id(\"hans kelsen\")\n",
    "\n",
    "b = ftm.model.make_entity(\"Person\")\n",
    "b.add(\"name\", \"Prof. Dr. hans kelsen\")\n",
    "b.add(\"birthDate\", \"1908\")\n",
    "b.add(\"title\", \"Prof.\")\n",
    "b.make_id(\"Prof. Dr. Hans Kelsen\")\n",
    "\n",
    "match = enricher.make_match(a, b)\n",
    "match.decision = match.SAME\n",
    "linker_exmpl.add(match)\n",
    "\n",
    "merged_ent  = a.merge(b)\n",
    "{\n",
    "    \"a\": a.id,\n",
    "    \"b\": b.id,\n",
    "    \"merged\": merged_ent.id,\n",
    "    \"result\": merged_ent.to_dict()[\"properties\"]}"
   ]
  },
  {
   "source": [
    "## On data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logic adapted form https://github.com/alephdata/followthemoney/blob/6cb55e319f69443dff17bf1ee5dd1a37a31b5c4a/followthemoney/cli/dedupe.py\n",
    "\n",
    "linker = Linker(model)\n",
    "for match in matches: \n",
    "    linker.add(match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeEntities(inpath, outfile, linker):\n",
    "    infile = open(inpath)\n",
    "\n",
    "    with infile as f:\n",
    "        for line in f:\n",
    "            entity = model.get_proxy(json.loads(line))\n",
    "            applied = linker.apply(entity)\n",
    "            \n",
    "\n",
    "            json_ent = json.dumps(applied.to_dict(), sort_keys=True)\n",
    "            outfile.write(json_ent + \"\\n\")\n",
    "\n",
    "nb_merge_output = path + \"/nb-merge-output\"\n",
    "merged_path  = nb_merge_output + \"/merged.json\"\n",
    "outfile = open(merged_path,  \"w\")\n",
    "mergeEntities(ep_path , outfile, linker)\n",
    "mergeEntities(ma_path, outfile, linker)\n",
    "merged_aggr_path = nb_merge_output + \"/merged_aggr.json\""
   ]
  },
  {
   "source": [
    "### Aggregate CLI command"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$merged_path\" \"$merged_aggr_path\"\n",
    "cat $1 | ftm aggregate -o $2\n"
   ]
  },
  {
   "source": [
    "# CLI\n",
    "I also implemented the merge-file-generator as a command-line tool in a more performant way. The `merger` package generates a matching file that links FtM IDs that have a common ID and calls `ftm link`, which applies the merges and `ftm aggregate` to actually merge them (see [fragmentation](https://followthemoney.readthedocs.io/en/latest/fragments.html))\n",
    "\n",
    "The CLI can either be used by setting the property argument to `wikidataId` or by leaving it empty, which goes through all properties of an entity, checks if the type is an identifier and emits an match object for any kind of identifier match. Therefore, this works for any identifier in the FtM ontology.\n",
    "\n",
    "```\n",
    "python wd_merger.py id-match -i <dir> | python wd_merger.py merger -i <dir> | ftm aggregate -o <outfile> \n",
    "```\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install ./merger"
   ]
  },
  {
   "source": [
    "Due to duplicates within everypolitician regarding Wikidata IDs, we have more matches (685):"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli_merge_output = path + \"cli-merge-output\"\n",
    "cli_merged = cli_merge_output + \"/merged.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: Entity '2e685fde839d0217b1ac6455d406e9aef6991da9'' and 'c4e9d9cf34e6f9c5b319edb4e1a1aa6e946624c1' cannot be matched. Incompatible types <Organization, Person>\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$path\" \"$cli_merged\"\n",
    "merger pmatch -i $1 | merger pmerge  -i $1 | ftm aggregate -o $2 "
   ]
  },
  {
   "source": [
    "This generates a `matches.json`, which can be used to stream to an Aleph instance or ingest into a Neo4j db.\n",
    "\n",
    "Aleph:\n",
    "```\n",
    "cat matches.json | alephclient --host https://aleph.occrp.org --api-key <api-key> write-entities -f <collection_id> \n",
    "```\n",
    "\n",
    " Neo4j:\n",
    " ```\n",
    " cat matches.json | ftm export-cypher | cypher-shell -u user -p password\n",
    " ```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Enrich\n",
    "Basic enrichment can also also be perfromed.\n",
    "Two commands are called here:\n",
    "\n",
    "1. The `extract` command pulls out entities that have Wikidata IDs from a file or path of FtM entity JSONs and writes them to stdout (seperated by newlines).\n",
    "2. The `enrich` command actually performs the enrichment by calling the Wikidata API. Currently, there are no linking entities caputured and the requests are performed synchronously.\n",
    "\n",
    "Here, we only do this for the dataset from meineabgeordneten.at as it is smaller. Note that this process takes some time. For reproducibility, this has also been done in advance."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_output = path + \"cli_enrich_output\" \n",
    "enrich_output_new = enrich_output + \"/enriched_MA.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$ma_path\" \"$enrich_output_new\"\n",
    "merger extract -i $1 -p wikidataId | merger enrich -o $2"
   ]
  },
  {
   "source": [
    "All 745 person entities with Wikidata ID could be enriched."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "745"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "enriched = read_ftm_json(enrich_output + \"/enriched_MA_queried.json\")\n",
    "len(enriched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'origin': 'memorious',\n",
       " 'updated_at': '2019-05-08T01:55:52',\n",
       " 'id': 'cfdfd70fdf76870ec3f0d998ce7e2ff83f516674',\n",
       " 'schema': 'Person',\n",
       " 'properties': {'alias': ['Beate Meinl-Reisinger'],\n",
       "  'birthDate': ['1978-04-25'],\n",
       "  'firstName': ['Beate'],\n",
       "  'gender': ['female'],\n",
       "  'lastName': ['Meinl-Reisinger'],\n",
       "  'name': ['Mag. Beate Meinl-Reisinger, MES'],\n",
       "  'nationality': ['at'],\n",
       "  'title': ['Mag.', 'MES'],\n",
       "  'topics': ['role.pep'],\n",
       "  'website': ['https://facebook.com/BeateMeinl', 'https://twitter.com/bmeinl'],\n",
       "  'wikidataId': ['Q15787318'],\n",
       "  'wikipediaUrl': ['https://fr.wikipedia.org/wiki/Beate_Meinl-Reisinger',\n",
       "   'https://de.wikipedia.org/wiki/Beate_Meinl-Reisinger',\n",
       "   'https://hu.wikipedia.org/wiki/Beate_Meinl-Reisinger',\n",
       "   'https://pl.wikipedia.org/wiki/Beate_Meinl-Reisinger',\n",
       "   'https://en.wikipedia.org/wiki/Beate_Meinl-Reisinger']}}"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "# Item from Everypolitician.\r\n",
    "every_polit[\"Q15787318\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'id': '356d3d7712c6ed51f31db7768a562c94d8f23c5d',\n",
       " 'schema': 'Person',\n",
       " 'properties': {'alias': ['Майнль-Райзингер, Беата'],\n",
       "  'birthDate': ['1978-04-25T00:00:00'],\n",
       "  'birthPlace': ['Vienna'],\n",
       "  'description': ['Austrian jurist and politician'],\n",
       "  'email': ['mailto:beate.meinl@neos.eu'],\n",
       "  'firstName': ['Beate'],\n",
       "  'gender': ['female'],\n",
       "  'lastName': ['Meinl-Reisinger'],\n",
       "  'name': ['Beate Meinl-Reisinger'],\n",
       "  'nationality': ['at'],\n",
       "  'title': ['Magister Juris', 'Master of European Studies'],\n",
       "  'website': ['https://beatemeinl.com/'],\n",
       "  'wikidataId': ['Q15787318']}}"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "# Item from Wikidata(enrichment).\n",
    "enriched[\"Q15787318\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'origin': 'memorious',\n",
       " 'id': 'acee34362b60a3d4d8978c0bb0350dd1df447e84',\n",
       " 'schema': 'Person',\n",
       " 'properties': {'birthDate': ['1978-04-25'],\n",
       "  'birthPlace': ['Wien'],\n",
       "  'country': ['at'],\n",
       "  'email': ['beate.meinl@neos.eu'],\n",
       "  'firstName': ['Beate'],\n",
       "  'lastName': ['Meinl-Reisinger'],\n",
       "  'name': ['Beate Meinl-Reisinger'],\n",
       "  'sourceUrl': ['https://www.meineabgeordneten.at/Abgeordnete/Beate.Meinl-Reisinger'],\n",
       "  'summary': ['Abgeordnete zum Nationalrat'],\n",
       "  'title': ['Mag.a'],\n",
       "  'website': ['https://www.linkedin.com/in/beate-meinl-reisinger-0a827a84',\n",
       "   'https://www.facebook.com/beate.meinlreisinger',\n",
       "   'https://www.facebook.com/BeateMeinl',\n",
       "   'https://www.instagram.com/beate_meinl_reisinger/',\n",
       "   'https://twitter.com/BMeinl'],\n",
       "  'wikidataId': ['Q15787318']}}"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "# Item from meineabgeordneten.at.\n",
    "mein_abg[\"Q15787318\"].to_dict()"
   ]
  },
  {
   "source": [
    "# Push back to Aleph\n",
    "If Aleph is running:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$host\" \"$api_key\" \"$target_collection_id\"  \"$cli_merged\"\n",
    "cat $4 | alephclient --host $1 --api-key $2 write-entities -f $3"
   ]
  }
 ]
}